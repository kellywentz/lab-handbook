# Research Best Practices {#sec-research-best-practices}

This chapter outlines the standards and best practices for conducting research in the Brain Development & Education Lab.
These practices ensure the integrity, reproducibility, and ethical conduct of our research.

## Principles of research integrity {#research-integrity}

**Core principles:**

-   *Honesty:* Report data and findings truthfully

-   *Accuracy:* Strive for accuracy in all aspects of research

-   *Transparency:* Be open about methods, data, and limitations

-   *Reproducibility:* Conduct research in ways that others can verify and build upon

-   *Respect:* Respect participants, collaborators, and the scientific community

**Scientific misconduct:**

The lab has zero tolerance for research misconduct, including:

-   Fabrication of data or results

-   Falsification or manipulation of data

-   Plagiarism

-   Misrepresentation of contributions or authorship

If you observe or suspect research misconduct, report it immediately to Jason Yeatman.

## Data security and confidentiality {#sec-data-security}

**Protecting participant data:**

Our work involves sensitive data from children, schools, and families.
Protecting this data is both an ethical obligation and a legal requirement.

**Rules for handling sensitive data:**

-   *Never* email files containing personally identifiable information (PII)

-   *Never* store participant data on personal devices

-   *Never* share data via public Slack channels (use private channels or DMs), better yet only share secure Google Drive links to the data

-   *Always* use secure, Stanford-approved storage (Google Drive, BigQuery)

-   *Always* check IRB and DUA protocols before sharing data, even within the lab

-   *Always* de-identify data when possible

-   *Always* use minimum necessary data (only access what you need)

**What counts as identifiable information:**

-   Names, addresses, phone numbers, email addresses

-   Student/teacher ID numbers

-   School names (in some cases)

-   Dates of birth

-   Neuroimaging data (can reconstruct facial features)

-   Assessment scores linked to individuals

-   Small-cell data that could identify individuals

**When in doubt, ask.** It's better to check than to inadvertently violate confidentiality.

**Data sharing via Google Drive:**

-   Share links to files/folders rather than downloading and re-uploading

-   Use "restricted" sharing settings (not "anyone with link")

-   Grant access only to people who need it and have IRB and DUA approval

-   Remove access when team members leave the lab and/or no longer need data (see @sec-offboarding for more information)

**Working remotely:**

-   Use [Stanford VPN](https://uit.stanford.edu/service/vpn) when accessing sensitive data remotely

-   Ensure your home wifi is password-protected

-   Don't work with sensitive data in public spaces where screens can be viewed

-   Lock your computer when stepping away

-   If you plan to work outside of the United States, please consult with your team lead and Jason Yeatman to discuss [data security and procedures](https://global.stanford.edu/plan-your-global-activity/hr-and-employment/stanford-personnel-working-abroad)

## External data and Data Use Agreements (DUAs) {#sec-dua}

**Working with school/district data:**

-   Ensure a Data Use Agreement (DUA) is in place *before* receiving data

-   Store data according to DUA specifications

-   Use data only for approved purposes

-   Share data only with approved individuals

-   Delete or return data according to DUA terms

-   Report any data breaches immediately

**DUA tracking:**

-   Partnerships team tracks DUAs in Monday.com

-   Ensure you are listed on DUA before accessing partner and student data

-   Understand restrictions on data use and sharing

**Combining ROAR data with external data:**

-   Ensure IRB and DUA approval for data linkage

-   Maintain appropriate security for combined datasets

-   Document linkage procedures

-   Be especially careful with identifiable linked data

## Data management and organization {#sec-data-management}

*Review @sec-data-management-plan for more detailed information* on data management planning

**General principles:**

-   All research data must be stored on Stanford-approved systems (Google Drive, BigQuery)

-   Data should never be stored solely on personal devices or non-Stanford cloud services

-   Maintain organized, well-documented files that others can understand

-   Use clear, consistent naming conventions

-   Document your work as you go, not retrospectively

**Google Drive organization:**

Google Drive is the primary storage location for:

-   Meeting notes (internal and external)

-   School, district, and student research data

-   In-lab participant data

-   Presentations and feedback notes

-   Project management documentation

-   Testing materials and documentation

-   Validation data

**Best practices:**

-   Save all work to appropriate shared drives (not personal drives)

-   Use descriptive folder structures

-   Include README files in project folders explaining organization

-   Never duplicate large datasets

-   Clean up and delete unnecessary or duplicate files regularly

**Access management:**

-   Data access is provided in line with the principle of least privilege

-   If you need access to specific folders or datasets, contact Carrie Townley-Flores or Jason Yeatman

## File naming conventions {#sec-file-naming}

Consistent file naming makes it easier for everyone to find and understand files.

**General format:**

`projectname_filedescription_version_YYYY-MM-DD.ext`

**Examples:**

`validation_analysis_v1_2025-01-22.Rmd`

`partnermeeting_notes_2026-03-01.docx`

`word_runs_2024-12-10.csv`

**Guidelines:**

-   Use dates in YYYY-MM-DD format to inform when data was pulled/cleaned

-   Use underscores or hyphens instead of spaces

-   Be descriptive but concise

-   Include version numbers for documents that go through multiple drafts

-   Use meaningful abbreviations consistently

-   Avoid special characters (except \_ and -)

## Data cleaning and processing {#sec-data-cleaning-processing}

**General principles:**

-   Never modify raw data files—always create processed versions

-   Document all cleaning steps in code

-   Save intermediate processed datasets with clear labels and dates

-   Use [roarutility R package](https://github.com/yeatmanlab/roarutility) (by Kelly Wentzlof) to help clean and process ROAR data

**Data cleaning workflow:**

1.  *Raw data:* Original, unmodified data

2.  *Cleaning code:* Documented code that processes raw data

3.  *Cleaned data:* Processed data ready for analysis

4.  *Analysis code:* Code that analyzes cleaned data

5.  *Results:* Outputs from analyses

**Documentation:**

For each dataset, maintain:

-   *Data dictionary:* Description of all variables

-   *Codebook:* Information about data querying, processing, cleaning

-   *README:* Overview and instructions for using the data

**Common data cleaning tasks:**

-   Removing duplicates

-   Handling missing data

-   Recoding variables

-   Creating derived variables

-   Filtering to relevant subset

-   Merging datasets

Document decisions about:

-   How missing data is handled

-   Which observations are excluded and why

-   How variables are recoded or computed

-   Any assumptions made in processing

## Data analysis and code {#sec-data-analysis-code}

**Reproducibility:**

All analyses should be reproducible—someone else should be able to run your code and get the same results.

**Requirements:**

-   Fill out a project management document for any new projects/analyses (see @sec-project-management-doc for more information and a project management template)

-   Use code (R, Python, etc.) rather than point-and-click software when possible

-   Write clear, well-commented code (good rule of thumb: a comment for every couple lines of code)

-   Use version control (GitHub) for analysis code (backs up code and allows for easy collaboration)

-   Use relative file paths (not absolute paths specific to your computer)

-   Set random seeds for analyses involving randomization

**Code documentation:**

-   Include a README explaining what each script does within the project repository

-   Comment your code explaining why, not just what

-   Use meaningful variable names

-   Break complex code into smaller, well-named functions and chunks

-   Include information about software/package versions used

**Using R:**

-   Use the [roarutility R package](https://github.com/yeatmanlab/roarutility) (by Kelly Wentzlof) for common ROAR data processing tasks

-   Follow tidyverse style guidelines

-   Use RStudio projects, markdowns, and quarto documents for organization

## Version control with GitHub {#sec-version-control-git}

In this lab, GitHub is used for:

-   Backing up and versioning code

-   Collaborating on analysis code

-   Tracking issues and tasks (for developers)

-   Hosting documentation (ROAR Technical Manual, ROAR docs) and software (ROAR Data Dashboard, [roarutility R package](https://github.com/yeatmanlab/roarutility))

-   Sharing code with collaborators

**Best practices:**

-   Commit early and often

-   Write clear, descriptive commit messages

-   *Don't commit any data*

-   Use .gitignore to exclude data files and outputs

-   Create branches for new features or analyses

-   Always use pull requests for code review prior to merging into main branch

-   Keep repositories organized and well-documented

**For researchers:**

-   See GitHub walk-through in [ROAR Researcher Documentation](https://yeatmanlab.github.io/roar-docs/researcher/data-tools/#github)

-   Create a repository for each major project or paper

-   Include a README with project description and script-level descriptions

-   Make code public upon publication (or earlier if appropriate) after consulting with Jason Yeatman

**For developers:**

-   See [ROAR Developer Documentation](https://yeatmanlab.github.io/roar-docs/developer/) for detailed Git workflows and standards

## Data retention and archival {#sec-data-retention-archival}

**During active research:**

-   Keep all data and code organized and accessible

-   Back up important files and scripts regularly

-   Maintain clear documentation

**After publication:**

-   Archive data and code for published papers

-   Make code publicly available (GitHub)

-   Discuss data sharing plans with Jason Yeatman

**When leaving the lab:**

-   Ensure all data is on shared drives, not personal drives

-   Document where everything is located

-   Transfer ownership of files/folders as appropriate

-   See @sec-offboarding for more details

## Computational resources {#sec-computational-resources}

**Available resources:**

-   Personal computers (laptop, monitor, keyboard, etc.)

-   Stanford Google Workspace (Drive, Docs, Sheets, etc.)

-   BigQuery for large-scale data storage and retrieval

-   GitHub for version control

-   Stanford compute clusters (for intensive analyses)

-   Software licenses through Stanford

**Software:**

Commonly used software in the lab:

-   R and RStudio (statistical analysis)

-   Quarto (technical manual and documentation)

-   Python (development and analysis)

-   Git and GitHub (version control)

-   Slack, Zoom (communication)

-   Microsoft Outlook (meeting tracker, external communication)

-   Canva (graphics and presentations)

-   Monday.com (partnerships tracker)

## Getting help {#sec-research-contacts}

**Data and analysis questions:**

-   Kelly Wentzlof (R, statistics, ROAR data)

-   Jason Yeatman

-   Carrie Townley-Flores (R, statistics, organizational data)

-   Adam Richie-Halford (VS Code, ROAR development, technical infrastructure)

-   Lab meetings (for broader input)

**Data management questions:**

-   Kelly Wentzlof (ROAR data organization)

-   Carrie Townley-Flores (partnerships data, DUAs)

-   Adam Richie-Halford (ROAR BigQuery, development)

-   Kyle Montville (ROAR BigQuery)

**IRB and ethics questions:**

-   Carrie Townley-Flores (partnerships team leads)

-   Jason Yeatman

-   Sarahi Muñoz and May Fahrenthold (IRB coordinators)

-   Stanford IRB office

**Computing resources:**

-   Kelly Wentzlof (data science)

-   Adam Richie-Halford (development)

-   Jason Yeatman (major resource needs, cluster access)

-   Stanford IT

**When in doubt:**

-   Ask!
    It's better to ask than to make a mistake with data

-   Document your questions and the answers

-   Share solutions with the lab (e.g., in Slack)
